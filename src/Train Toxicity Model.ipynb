{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Toxicity Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook trains a model to detect toxicity in online comments. It uses a CNN architecture for text classification trained on the [Wikipedia Talk Labels: Toxicity dataset](https://figshare.com/articles/Wikipedia_Talk_Labels_Toxicity/4563973) and pre-trained GloVe embeddings which can be found at:\n",
    "http://nlp.stanford.edu/data/glove.6B.zip\n",
    "(source page: http://nlp.stanford.edu/projects/glove/).\n",
    "\n",
    "This model is a modification of [example code](https://github.com/fchollet/keras/blob/master/examples/pretrained_word_embeddings.py) found in the [Keras Github repository](https://github.com/fchollet/keras) and released under an [MIT license](https://github.com/fchollet/keras/blob/master/LICENSE). For further details of this license, find it [online](https://github.com/fchollet/keras/blob/master/LICENSE) or in this repository in the file KERAS_LICENSE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Instructions\n",
    "(TODO: nthain) - Move to README\n",
    "\n",
    "Prior to running the notebook, you must:\n",
    "\n",
    "* Download the [Wikipedia Talk Labels: Toxicity dataset](https://figshare.com/articles/Wikipedia_Talk_Labels_Toxicity/4563973)\n",
    "* Download pre-trained [GloVe embeddings](http://nlp.stanford.edu/data/glove.6B.zip)\n",
    "* (optional) To skip the training step, you will need to download a model and tokenizer file. We are looking into the appropriate means for distributing these (sometimes large) files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO from model_tool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from model_tool import ToxModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SPLITS = ['train', 'dev', 'test']\n",
    "\n",
    "wiki = {}\n",
    "debias = {}\n",
    "random = {}\n",
    "for split in SPLITS:\n",
    "    wiki[split] = '../data/wiki_%s.csv' % split\n",
    "    debias[split] = '../data/wiki_debias_%s.csv' % split\n",
    "    random[split] = '../data/wiki_debias_random_%s.csv' % split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 99157 samples, validate on 33283 samples\n",
      "Epoch 1/6\n",
      "99157/99157 [==============================] - 224s - loss: 0.2115 - acc: 0.9239 - val_loss: 0.1504 - val_acc: 0.9450\n",
      "Epoch 2/6\n",
      "99157/99157 [==============================] - 214s - loss: 0.1441 - acc: 0.9480 - val_loss: 0.1351 - val_acc: 0.9486\n",
      "Epoch 3/6\n",
      "99157/99157 [==============================] - 203s - loss: 0.1290 - acc: 0.9528 - val_loss: 0.1225 - val_acc: 0.9547\n",
      "Epoch 4/6\n",
      "99157/99157 [==============================] - 207s - loss: 0.1184 - acc: 0.9568 - val_loss: 0.1194 - val_acc: 0.9549\n",
      "Epoch 5/6\n",
      "99157/99157 [==============================] - 255s - loss: 0.1098 - acc: 0.9597 - val_loss: 0.1158 - val_acc: 0.9575\n",
      "Epoch 6/6\n",
      "99157/99157 [==============================] - 268s - loss: 0.1034 - acc: 0.9617 - val_loss: 0.1182 - val_acc: 0.9549\n",
      "<keras.callbacks.History object at 0x12e14add0>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'cnn_debias_random_tox_v3'\n",
    "debias_random_model = ToxModel()\n",
    "debias_random_model.train(random['train'], random['dev'], text_column = 'comment', label_column = 'is_toxic', model_name = MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95864283651436777"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_test = pd.read_csv(random['test'])\n",
    "debias_random_model.score_auc(random_test['comment'], random_test['is_toxic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plain wikipedia model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 95692 samples, validate on 32128 samples\n",
      "Epoch 1/6\n",
      "95692/95692 [==============================] - 212s - loss: 0.2034 - acc: 0.9280 - val_loss: 0.1559 - val_acc: 0.9406\n",
      "Epoch 2/6\n",
      "95692/95692 [==============================] - 195s - loss: 0.1439 - acc: 0.9472 - val_loss: 0.1316 - val_acc: 0.9509\n",
      "Epoch 3/6\n",
      "95692/95692 [==============================] - 204s - loss: 0.1301 - acc: 0.9522 - val_loss: 0.1246 - val_acc: 0.9536\n",
      "Epoch 4/6\n",
      "95692/95692 [==============================] - 199s - loss: 0.1203 - acc: 0.9560 - val_loss: 0.1227 - val_acc: 0.9540\n",
      "Epoch 5/6\n",
      "95692/95692 [==============================] - 191s - loss: 0.1127 - acc: 0.9592 - val_loss: 0.1192 - val_acc: 0.9561\n",
      "Epoch 6/6\n",
      "95692/95692 [==============================] - 191s - loss: 0.1065 - acc: 0.9611 - val_loss: 0.1283 - val_acc: 0.9498\n",
      "<keras.callbacks.History object at 0x14028d7d0>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'cnn_wiki_tox_v3'\n",
    "wiki_model = ToxModel()\n",
    "wiki_model.train(wiki['train'], wiki['dev'], text_column = 'comment', label_column = 'is_toxic', model_name = MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96418448325075334"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_test = pd.read_csv(wiki['test'])\n",
    "wiki_model.score_auc(wiki_test['comment'], wiki_test['is_toxic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debiased model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Data prepared!\n",
      "Loading embeddings...\n",
      "Embeddings loaded!\n",
      "Building model graph...\n",
      "Training model...\n",
      "Train on 99157 samples, validate on 33283 samples\n",
      "Epoch 1/6\n",
      "99157/99157 [==============================] - 195s - loss: 0.2072 - acc: 0.9262 - val_loss: 0.1501 - val_acc: 0.9456\n",
      "Epoch 2/6\n",
      "99157/99157 [==============================] - 194s - loss: 0.1459 - acc: 0.9473 - val_loss: 0.1302 - val_acc: 0.9519\n",
      "Epoch 3/6\n",
      "99157/99157 [==============================] - 199s - loss: 0.1305 - acc: 0.9527 - val_loss: 0.1378 - val_acc: 0.9523\n",
      "Epoch 4/6\n",
      "99157/99157 [==============================] - 190s - loss: 0.1210 - acc: 0.9562 - val_loss: 0.1204 - val_acc: 0.9550\n",
      "Epoch 5/6\n",
      "99157/99157 [==============================] - 188s - loss: 0.1134 - acc: 0.9591 - val_loss: 0.1222 - val_acc: 0.9562\n",
      "Epoch 6/6\n",
      "99157/99157 [==============================] - 189s - loss: 0.1063 - acc: 0.9611 - val_loss: 0.1151 - val_acc: 0.9572\n",
      "<keras.callbacks.History object at 0x157ffb950>\n",
      "Model trained!\n",
      "Saving model...\n",
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'cnn_debias_tox_v3'\n",
    "debias_model = ToxModel()\n",
    "debias_model.train(debias['train'], debias['dev'], text_column = 'comment', label_column = 'is_toxic', model_name = MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97214632823959757"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debias_test = pd.read_csv(debias['test'])\n",
    "debias_model.prep_data_and_score(debias_test['comment'], debias_test['is_toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
